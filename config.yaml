LOGGING_LEVEL: "DEBUG"

# Anki deck name
DECK_NAME: "mnemorai"

# The model to use for grapheme to phoneme conversion (G2P)
G2P:
  MODEL: "charsiu/g2p_multilingual_byT5_small_100"
  TOKENIZER: "google/byt5-small"
  LANGUAGE_JSON: "data/languages.json"
  IPA_REPO: "StephanAkkerman/english-words-IPA"
  IPA_FILE: "en_US.csv"

# The model to use for generating the mnemonic and creating the verbal cue
LLM:
  # We recommend the models from unsloth: https://docs.unsloth.ai/get-started/all-our-models
  SMALL_MODEL: 
    NAME: "unsloth/Qwen2.5-3B-Instruct-bnb-4bit" 
    VRAM: 3 # 3GB vram
  MEDIUM_MODEL: 
    NAME: "unsloth/Qwen2.5-7B-Instruct-bnb-4bit"
    VRAM: 6 # 6GB vram
  LARGE_MODEL: 
    NAME: "unsloth/Qwen2.5-14B-Instruct-bnb-4bit"
    VRAM: 9 # 9GB vram
  # Options are: None, 4bit, 8bit
  # Use None if you use an unsloth model (these are already quantized)
  QUANTIZATION: None
  USE_LORA: False
  LORA: "StephanAkkerman/Phi-3-mini-4k-instruct-QLoRA-4bit-Mnemonic"
  DELETE_AFTER_USE: False
  OFFLOAD: True
  PARAMS:
    #temperature: 0.5

# The model to use for generating the image
IMAGE_GEN:
  SMALL_MODEL: 
    NAME: stabilityai/stable-diffusion-2
    VRAM: 3 # 3GB vram
  MEDIUM_MODEL: 
    NAME: stabilityai/sdxl-turbo 
    VRAM: 6 # 6GB vram
  LARGE_MODEL: 
    NAME: Efficient-Large-Model/Sana_600M_512px_diffusers
    VRAM: 9 # 9GB vram, less with quantization
  OUTPUT_DIR: "imagine/generated-img"
  # Options are: None, 4bit, 8bit
  QUANTIZATION: None # only supported for Sana at the moment
  DELETE_AFTER_USE: False
  OFFLOAD: True # This must be False if quantization != None
  PARAMS:
    num_inference_steps: 40
    height: 512
    width: 512